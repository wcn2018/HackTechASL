{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports:\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets, models\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "# %matplotlib inline \n",
    "#Model Loader and Inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The original method definitions\n",
    "\n",
    "def set_requires_grad(model, grad_tf, exclude):\n",
    "    if grad_tf:\n",
    "        for param in model.parameters():\n",
    "            if param.name in exclude:\n",
    "                param.requires_grad = True\n",
    "            else: \n",
    "                param.requires_grad = False\n",
    "\n",
    "#used to init weights to xavier tensor.\n",
    "def init_xavier(tens): #model m, string of type to init, layers in\n",
    "    #not at all sure if the following method for inits works.\n",
    "    size = tens.size()\n",
    "    print(size)\n",
    "    linear = torch.nn.Linear(size[0], size[1], bias = True)\n",
    "    torch.nn.init.xavier_normal_(linear.weight)\n",
    "\n",
    "# The base inceptionv3 model we will be using\n",
    "model_ft = models.inception_v3(pretrained = True)\n",
    "\n",
    "# A function for initializing our model, restricted to the layers defined\n",
    "# in inceptionv3 (one FC layer). FUTURE WORK SHOULD FIND WAY TO IMPLEMENT MORE FC LAYERS.\n",
    "def initialize_model(model_name, num_classes, feature_extract, reinit_type, use_pretrained = True,):\n",
    "    # model_name is (inception), num_classes: 26, feature_extract = grad_tf = false, \n",
    "    # pretrained = True for Inception, reinit_type = set of weights to init with. (\"xavier\")\n",
    "    if model_name == \"inception\":\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_requires_grad(model_ft, feature_extract, [\"fc\"])\n",
    "        #Following redefines the fc layer to be the layer from Garcia-Viesca\n",
    "        #The input data for this:\n",
    "    \n",
    "        #AUXILARY NET:\n",
    "        num_in_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        print(num_in_ftrs)\n",
    "        model_ft.AuxLogits.fc = torch.nn.Linear(num_in_ftrs, num_classes)\n",
    "        torch.nn.init.xavier_normal_(model_ft.AuxLogits.fc.weight)\n",
    "        \n",
    "        #model_ft.AuxLogits.fc = torch.nn.Softmax(model_ft.AuxLogits.fc.weight,1)\n",
    "        #model_ft.AuxLogits.fc.weight = init_xavier(model_ft.AuxLogits.fc.weight)\n",
    "        \n",
    "        #PRIMARY NET:\n",
    "        num_in_ftrs = model_ft.fc.in_features\n",
    "        print(num_in_ftrs)\n",
    "        model_ft.fc = torch.nn.Linear(num_in_ftrs, num_classes)\n",
    "        torch.nn.init.xavier_normal_(model_ft.fc.weight)\n",
    "        \n",
    "        #model_ft.fc = torch.nn.Softmax(model_ft.fc.weight,1)\n",
    "        #model_ft.fc.weight = init_xavier(model_ft.fc.weight)\n",
    "        \n",
    "        input_size = 299\n",
    "        \n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_requires_grad(model_ft, feature_extract,[\"final_conv\"])\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "    elif model_name == \"inception_real\":\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        #Following redefines the fc layer to be the layer from Garcia-Viesca\n",
    "        #The input data for this:\n",
    "    \n",
    "        #PRIMARY NET:\n",
    "        num_in_ftrs = model_ft.fc.in_features\n",
    "        model_ft.AuxLogits.fc = torch.nn.Linear(num_in_ftrs, num_classes)\n",
    "        torch.nn.init.xavier_normal_(model_ft.AuxLogits.fc.weight)\n",
    "        input_size = 299\n",
    "        \n",
    "    elif model_name == \"squeezenet_real\":\n",
    "        model_ft = models.squeezenet1_0(pretrained=True)\n",
    "        set_requires_grad(model_ft, False,[])\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    return model_ft, input_size\n",
    "\n",
    "img = Image.open(\"./asl_train/Z/Z1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z\n"
     ]
    }
   ],
   "source": [
    "model_ft, input_size = initialize_model(\"squeezenet\", 26, True, \"xavier\")\n",
    "state_dict = torch.load(\"./best_epoch_SD.pt\")\n",
    "model_ft.load_state_dict(state_dict)\n",
    "model_ft.eval()\n",
    "\n",
    "def infer(model_ft, img):\n",
    "    size = 224\n",
    "    TRANSFORM = transforms.Compose([\n",
    "        transforms.Resize((size,size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    img = TRANSFORM(img).float()\n",
    "    img = img.view(-1,3,size,size)\n",
    "    img.requires_grad = True\n",
    "    #print(img)\n",
    "    outputs = model_ft(img)\n",
    "    macs = torch.argmax(outputs) \n",
    "    return chr(macs+97)\n",
    "\n",
    "print(infer(model_ft, img))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
